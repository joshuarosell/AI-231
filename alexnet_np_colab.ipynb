{"cells":[{"cell_type":"markdown","metadata":{"id":"J1HyxnhXrfQr"},"source":["Mount Google Drive, Validation Tar + Devkit"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45169,"status":"ok","timestamp":1758158861645,"user":{"displayName":"Joshua Rosell","userId":"16663369772013986826"},"user_tz":-480},"id":"QlQ8gDf_phtu","jupyter":{"outputs_hidden":true},"outputId":"c3998f41-d701-4e9e-b578-2f743dc79df6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hPython: 3.12.11 | Torch: 2.8.0+cu126 | CUDA available: True\n","Mounted at /content/drive\n","total 0\n","lrwxrwxrwx 1 root root 58 Sep 18 01:27 ILSVRC2012_devkit_t12.tar.gz -> '/content/drive/MyDrive/AI 231/ILSVRC2012_devkit_t12.tar.gz'\n","lrwxrwxrwx 1 root root 52 Sep 18 01:27 ILSVRC2012_img_val.tar -> '/content/drive/MyDrive/AI 231/ILSVRC2012_img_val.tar'\n"]}],"source":["# Install & setup\n","!pip -q install -U torch torchvision tqdm cupy-cuda12x\n","\n","import os, sys, torch\n","from google.colab import drive\n","\n","print(\"Python:\", sys.version.split()[0], \"| Torch:\", torch.__version__,\n","      \"| CUDA available:\", torch.cuda.is_available())\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","VAL_TAR    = \"/content/drive/MyDrive/AI 231/ILSVRC2012_img_val.tar\"\n","DEVKIT_TAR = \"/content/drive/MyDrive/AI 231/ILSVRC2012_devkit_t12.tar.gz\"\n","\n","IMAGENET_ROOT = \"/content/imagenet_root\"\n","os.makedirs(IMAGENET_ROOT, exist_ok=True)\n","\n","# Symlink (or copy) the archives with the exact filenames torchvision expects\n","!ln -sf \"$VAL_TAR\"    \"$IMAGENET_ROOT/ILSVRC2012_img_val.tar\"\n","!ln -sf \"$DEVKIT_TAR\" \"$IMAGENET_ROOT/ILSVRC2012_devkit_t12.tar.gz\"\n","\n","!ls -lh \"$IMAGENET_ROOT\""]},{"cell_type":"markdown","metadata":{"id":"sVmwQyXFrfQw"},"source":["Load Validation Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167905,"status":"ok","timestamp":1758159035912,"user":{"displayName":"Joshua Rosell","userId":"16663369772013986826"},"user_tz":-480},"id":"JA4cKpSs3QGF","jupyter":{"outputs_hidden":true},"outputId":"97012880-d908-4222-bd1b-bb3e33fdde2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Val size: 50000\n","(512, 3, 224, 224) (512,)\n"]}],"source":["# Dataset + transforms\n","import scipy\n","\n","from torchvision.datasets import ImageNet\n","from torchvision.models import alexnet, AlexNet_Weights\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","# Use official AlexNet transforms (resize 256 -> center-crop 224 -> normalize)\n","weights = AlexNet_Weights.IMAGENET1K_V1\n","preprocess = weights.transforms()\n","\n","# This parses devkit and extracts val on first run\n","val_ds = ImageNet(root=IMAGENET_ROOT, split=\"val\", transform=preprocess)\n","print(\"Val size:\", len(val_ds))\n","\n","# Collate to NumPy (CHW float32) + labels (int64)\n","def collate_fn_numpy(batch):\n","    import torch\n","    imgs_t = torch.stack([img for (img, _) in batch], dim=0)     # (N,3,224,224) torch\n","    labels_t = torch.tensor([lab for (_, lab) in batch], dtype=torch.long)\n","    return imgs_t.numpy(), labels_t.numpy()\n","\n","batch_size  = 512\n","num_workers = 2\n","val_loader_np = DataLoader(\n","    val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n","    pin_memory=False, collate_fn=collate_fn_numpy\n",")\n","# Smoke test: fetch one batch\n","xb, yb = next(iter(val_loader_np))\n","print(xb.shape, yb.shape)"]},{"cell_type":"markdown","metadata":{"id":"2XIp0QxirfQx"},"source":["Numpy Alexnet Implementation"]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true,"id":"1QJ2uExppht1","jupyter":{"outputs_hidden":true},"executionInfo":{"status":"ok","timestamp":1758159045917,"user_tz":-480,"elapsed":7,"user":{"displayName":"Joshua Rosell","userId":"16663369772013986826"}}},"outputs":[],"source":["# NumPy AlexNet model\n","import numpy as np\n","from numpy.lib.stride_tricks import sliding_window_view\n","\n","def kaiming_normal(shape, fan_in=None, rng=None):\n","    rng = rng or np.random\n","    if fan_in is None:\n","        if len(shape) == 4:  # (C_out, C_in, KH, KW)\n","            fan_in = shape[1] * shape[2] * shape[3]\n","        elif len(shape) == 2:  # (out, in)\n","            fan_in = shape[1]\n","        else:\n","            fan_in = np.prod(shape)\n","    std = np.sqrt(2.0 / fan_in)\n","    return (rng.standard_normal(size=shape).astype(np.float32) * std).astype(np.float32)\n","\n","def xavier_normal(shape, rng=None):\n","    rng = rng or np.random\n","    if len(shape) == 4:\n","        fan_in = shape[1] * shape[2] * shape[3]\n","        fan_out = shape[0]\n","    else:\n","        fan_in, fan_out = shape[1], shape[0]\n","    std = np.sqrt(2.0 / (fan_in + fan_out))\n","    return (rng.standard_normal(size=shape).astype(np.float32) * std).astype(np.float32)\n","\n","def pad2d(x, pad):\n","    if pad == 0: return x\n","    return np.pad(x, ((0,0),(0,0),(pad,pad),(pad,pad)), mode='constant')\n","\n","class Conv2D:\n","    def __init__(self, in_ch, out_ch, k, stride=1, padding=0, W=None, b=None, rng=None):\n","        self.in_ch, self.out_ch = in_ch, out_ch\n","        self.k, self.stride, self.padding = k, stride, padding\n","        self.W = kaiming_normal((out_ch, in_ch, k, k), rng=rng) if W is None else W.astype(np.float32)\n","        self.b = np.zeros((out_ch,), dtype=np.float32) if b is None else b.astype(np.float32)\n","\n","    def __call__(self, x):\n","        # x: (N,C,H,W)\n","        x = pad2d(x, self.padding)\n","        N, C, H, W = x.shape\n","        KH = KW = self.k\n","        # (N, C, H-KH+1, W-KW+1, KH, KW)\n","        win = sliding_window_view(x, (KH, KW), axis=(-2, -1))\n","        win = win[:, :, ::self.stride, ::self.stride, :, :]     # stride\n","        N, C, H_out, W_out, _, _ = win.shape\n","        # reshape to GEMM: (N, H_out*W_out, C*KH*KW)\n","        cols = win.transpose(0,2,3,1,4,5).reshape(N, H_out*W_out, C*KH*KW)\n","        W_col = self.W.reshape(self.out_ch, C*KH*KW)            # (C_out, C*KH*KW)\n","        out = np.matmul(cols, W_col.T) + self.b.reshape(1,1,-1) # (N, H_out*W_out, C_out)\n","        return out.transpose(0,2,1).reshape(N, self.out_ch, H_out, W_out)\n","\n","class ReLU:\n","    def __call__(self, x): return np.maximum(x, 0)\n","\n","class MaxPool2D:\n","    def __init__(self, k=3, stride=2): self.k, self.stride = k, stride\n","    def __call__(self, x):\n","        N, C, H, W = x.shape\n","        KH = KW = self.k\n","        win = sliding_window_view(x, (KH, KW), axis=(-2, -1))    # (N,C,H-KH+1,W-KW+1,KH,KW)\n","        win = win[:, :, ::self.stride, ::self.stride, :, :]\n","        return win.max(axis=(-2, -1))                            # max over KH,KW\n","\n","class Dropout:\n","    def __init__(self, p=0.5): self.p = p\n","    def __call__(self, x, train=False, rng=None):\n","        if not train or self.p <= 0.0: return x\n","        rng = rng or np.random\n","        mask = (rng.rand(*x.shape).astype(np.float32) > self.p).astype(np.float32)\n","        return x * mask / (1.0 - self.p)\n","\n","class Flatten:  # (N,C,H,W) -> (N, C*H*W)\n","    def __call__(self, x): return x.reshape(x.shape[0], -1)\n","\n","class Linear:\n","    def __init__(self, in_f, out_f, W=None, b=None, rng=None):\n","        self.W = xavier_normal((out_f, in_f), rng=rng) if W is None else W.astype(np.float32)\n","        self.b = np.zeros((out_f,), dtype=np.float32) if b is None else b.astype(np.float32)\n","    def __call__(self, x): return x @ self.W.T + self.b\n","\n","class AlexNetNP:\n","    \"\"\"\n","    NumPy-only AlexNet forward pass (no LRN). Input: (N,3,224,224)\n","    Matches torchvision's canonical AlexNet used for ImageNet-1K.\n","    \"\"\"\n","    def __init__(self, num_classes=1000, seed=0):\n","        np.random.seed(seed)\n","        # Feature extractor\n","        self.conv1 = Conv2D(3,   64, k=11, stride=4, padding=2)\n","        self.relu1 = ReLU()\n","        self.pool1 = MaxPool2D(k=3, stride=2)\n","\n","        self.conv2 = Conv2D(64, 192, k=5, stride=1, padding=2)\n","        self.relu2 = ReLU()\n","        self.pool2 = MaxPool2D(k=3, stride=2)\n","\n","        self.conv3 = Conv2D(192, 384, k=3, stride=1, padding=1)\n","        self.relu3 = ReLU()\n","        self.conv4 = Conv2D(384, 256, k=3, stride=1, padding=1)\n","        self.relu4 = ReLU()\n","        self.conv5 = Conv2D(256, 256, k=3, stride=1, padding=1)\n","        self.relu5 = ReLU()\n","        self.pool5 = MaxPool2D(k=3, stride=2)\n","\n","        self.flatten = Flatten()\n","\n","        # Classifier\n","        self.drop1 = Dropout(0.5)\n","        self.fc1   = Linear(256*6*6, 4096)\n","        self.relu6 = ReLU()\n","        self.drop2 = Dropout(0.5)\n","        self.fc2   = Linear(4096, 4096)\n","        self.relu7 = ReLU()\n","        self.fc3   = Linear(4096, num_classes)\n","\n","    def forward(self, x, train=False):\n","        x = self.conv1(x); x = self.relu1(x); x = self.pool1(x)\n","        x = self.conv2(x); x = self.relu2(x); x = self.pool2(x)\n","        x = self.conv3(x); x = self.relu3(x)\n","        x = self.conv4(x); x = self.relu4(x)\n","        x = self.conv5(x); x = self.relu5(x); x = self.pool5(x)   # -> (N,256,6,6)\n","        x = self.flatten(x)                                       # -> (N,9216)\n","        x = self.drop1(x, train=train); x = self.fc1(x); x = self.relu6(x)\n","        x = self.drop2(x, train=train); x = self.fc2(x); x = self.relu7(x)\n","        x = self.fc3(x)                                           # logits\n","        return x\n","\n","    def load_from_npz(self, npz_path):\n","        data = np.load(npz_path)\n","        # features\n","        self.conv1.W, self.conv1.b = data['features.0.weight'],  data['features.0.bias']\n","        self.conv2.W, self.conv2.b = data['features.3.weight'],  data['features.3.bias']\n","        self.conv3.W, self.conv3.b = data['features.6.weight'],  data['features.6.bias']\n","        self.conv4.W, self.conv4.b = data['features.8.weight'],  data['features.8.bias']\n","        self.conv5.W, self.conv5.b = data['features.10.weight'], data['features.10.bias']\n","        # classifier\n","        self.fc1.W, self.fc1.b     = data['classifier.1.weight'], data['classifier.1.bias']\n","        self.fc2.W, self.fc2.b     = data['classifier.4.weight'], data['classifier.4.bias']\n","        self.fc3.W, self.fc3.b     = data['classifier.6.weight'], data['classifier.6.bias']"]},{"cell_type":"markdown","metadata":{"id":"fYJ_bu4FrfQy"},"source":["Export Alexnet Weights"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4933,"status":"ok","timestamp":1758159069124,"user":{"displayName":"Joshua Rosell","userId":"16663369772013986826"},"user_tz":-480},"id":"9_aaqEoSpht2","jupyter":{"outputs_hidden":true},"outputId":"c40b4412-42c8-40b9-e53b-730a0e8359a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233M/233M [00:01<00:00, 207MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved alexnet_imagenet1k_v1.npz\n","NumPy model ready.\n"]}],"source":["# Export torchvision AlexNet weights to .npz and load into NumPy AlexNet\n","import numpy as np\n","import torch\n","from torchvision.models import alexnet, AlexNet_Weights\n","\n","# Export (once)\n","torch_model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1).eval()\n","sd = torch_model.state_dict()\n","np.savez(\"alexnet_imagenet1k_v1.npz\", **{k: v.cpu().numpy() for k,v in sd.items()})\n","print(\"Saved alexnet_imagenet1k_v1.npz\")\n","\n","# Load NumPy model + weights\n","model_np = AlexNetNP(num_classes=1000, seed=42)\n","model_np.load_from_npz(\"alexnet_imagenet1k_v1.npz\")\n","print(\"NumPy model ready.\")"]},{"cell_type":"markdown","metadata":{"id":"jZnwWjgjrfQy"},"source":["Evaluate Numpy Alexnet on Validation Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1288333,"status":"ok","timestamp":1758160366251,"user":{"displayName":"Joshua Rosell","userId":"16663369772013986826"},"user_tz":-480},"id":"JpK1WF--pht3","jupyter":{"outputs_hidden":true},"outputId":"6a17e2f7-a87f-4d93-ba6c-ddd95d503282"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 98/98 [21:28<00:00, 13.15s/it]"]},{"output_type":"stream","name":"stdout","text":["[NumPy AlexNet] Evaluated 50000 samples | Top-1: 0.5656 | Top-5: 0.7908\n","\n","\n","Validation Accuracy: 0.5656\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Evaluation loop (Top-1 / Top-5) with NumPy model\n","from tqdm import tqdm\n","import numpy as np\n","\n","def topk_hits(logits, labels, k):\n","    # logits: (N,1000) float32; labels: (N,) int64\n","    if k == 1:\n","        preds = np.argmax(logits, axis=1)\n","        return (preds == labels).sum()\n","    # partial top-k (unordered) is faster than full sort\n","    topk = np.argpartition(-logits, kth=k-1, axis=1)[:, :k]\n","    # membership test\n","    return sum(lbl in row for lbl, row in zip(labels, topk))\n","\n","NUM_VAL_SAMPLES = None  # set to None for full 50k (slow on CPU)\n","\n","top1 = top5 = n = 0\n","seen = 0\n","\n","for xb, yb in tqdm(val_loader_np, total=(len(val_ds) // val_loader_np.batch_size) + 1):\n","    if NUM_VAL_SAMPLES is not None and seen >= NUM_VAL_SAMPLES:\n","        break\n","    # Trim last batch if we would exceed the cap\n","    if NUM_VAL_SAMPLES is not None and seen + yb.shape[0] > NUM_VAL_SAMPLES:\n","        keep = NUM_VAL_SAMPLES - seen\n","        xb, yb = xb[:keep], yb[:keep]\n","\n","    logits = model_np.forward(xb, train=False)  # NumPy forward\n","    top1 += topk_hits(logits, yb, k=1)\n","    top5 += topk_hits(logits, yb, k=5)\n","    n += yb.shape[0]; seen += yb.shape[0]\n","\n","print(f\"[NumPy AlexNet] Evaluated {n} samples \"\n","      f\"| Top-1: {top1/n:.4f} | Top-5: {top5/n:.4f}\")\n","print(\"\\n\")\n","print(f\"Validation Accuracy: {top1/n:.4f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[{"file_id":"1DoOUbVITm_k0C_xLnDwU_NRb0nIMtn9w","timestamp":1757995383987}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}